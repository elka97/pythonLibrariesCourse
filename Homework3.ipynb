{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNJxEFTq6JrglpIut7NSHD0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elka97/pythonLibrariesCourse/blob/lesson1/Homework3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjdKwe8yvbei"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsLsEl38vvQb"
      },
      "source": [
        "# Тема “Обучение с учителем”\n",
        "Задание 1\n",
        "Импортируйте библиотеки pandas и numpy.\n",
        "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных.\n",
        "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки\n",
        "составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
        "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
        "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
        "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2oEbX_8v0Ob"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_boston\n",
        "boston = load_boston()\n",
        "X = pd.DataFrame(data=boston.data, columns=boston.feature_names)\n",
        "y = pd.DataFrame(data=boston.target, columns=['target'])\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf3qhhJXwnys"
      },
      "source": [
        "X.head(20), y.head(20)\n",
        "X.info(), y.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lANgb9CFxE4E"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D_P8tiAxk8M"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjxi_Gdwxxud"
      },
      "source": [
        "y_pred = lr.predict(X_test)\n",
        "# y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCglUMS1yoPO"
      },
      "source": [
        "# check_test = pd.DataFrame({\n",
        "#     \"y_test\": y_test[\"target\"],\n",
        "#     \"y_pred\": y_pred.flatten(),\n",
        "# })\n",
        "# check_test.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJcJiqxTzTml"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "R2 = r2_score(y_test[\"target\"], y_pred.flatten())\n",
        "R2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eQzR3FG3s9N"
      },
      "source": [
        "Задание 2\n",
        "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
        "Сделайте агрумент n_estimators равным 1000,\n",
        "max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
        "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
        "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
        "чтобы получить из датафрейма одномерный массив Numpy,\n",
        "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
        "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
        "Напишите в комментариях к коду, какая модель в данном случае работает лучше."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTKmiYue3wJU"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model= RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)\n",
        "model.fit(X_train, y_train.values[:, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r28vSzho4bZe"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBbh1iHn4xmm"
      },
      "source": [
        "R2 = r2_score(y_test[\"target\"], y_pred.flatten())\n",
        "R2\n",
        "# R2=0.8749965273218174 of RandomForestRegressor with params n_estimators=1000, max_depth=12(random_state=42)is better then R2=0.7112260057484974 of LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTFXY1qY5Y3P"
      },
      "source": [
        "*Задание 3\n",
        "Вызовите документацию для класса RandomForestRegressor,\n",
        "найдите информацию об атрибуте feature_importances_.\n",
        "С помощью этого атрибута найдите сумму всех показателей важности,\n",
        "установите, какие два признака показывают наибольшую важность."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYB7uNGo5a52"
      },
      "source": [
        "RandomForestRegressor?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5vhE5YD6xJ_"
      },
      "source": [
        "importances = model.feature_importances_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12BHy3mn7O-f"
      },
      "source": [
        "for i in range(X_train.shape[1]):\n",
        "  print(f\"{i + 1}. feature {cols[i]} {importances[i]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9gndU8T_Mex"
      },
      "source": [
        "check_importances = pd.DataFrame(data=importances.tolist(), index=cols.values, columns=[\"importances\"])\n",
        "check_importances.sort_values(by=\"importances\").tail(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59H6PSGYDH4y"
      },
      "source": [
        "*Задание 4\n",
        "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
        "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
        "Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
        "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
        "pd.options.display.max_columns = 100.\n",
        "Просмотрите первые 10 строк датафрейма df.\n",
        "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
        "Создайте объект Series под названием y из столбца Class.\n",
        "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
        "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
        "Просмотрите информацию о их форме.\n",
        "Для поиска по сетке параметров задайте такие параметры:\n",
        "parameters = [{'n_estimators': [10, 15],\n",
        "'max_features': np.arange(3, 5),\n",
        "'max_depth': np.arange(4, 7)}]\n",
        "Создайте модель GridSearchCV со следующими аргументами:\n",
        "estimator=RandomForestClassifier(random_state=100),\n",
        "param_grid=parameters,\n",
        "scoring='roc_auc',\n",
        "cv=3.\n",
        "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
        "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
        "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
        "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
        "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azcp6DW6DcIN"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S1R25DuD5cz"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "df = pd.read_csv(\"/gdrive/My Drive/Colab Notebooks/creditcard.csv\",  error_bad_lines=False)\n",
        "df.shape, df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTXwrGVXEcxX"
      },
      "source": [
        "pd.options.display.max_columns = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2r2itxTENJZ"
      },
      "source": [
        "df.Class.value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EiLcF4JEmIg"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOd2t-n_E5Oq"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b22b8EN2E9uE"
      },
      "source": [
        "X = df.drop(columns=[\"Class\"])\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKBvyU2-FN6q"
      },
      "source": [
        "y = pd.Series(df.Class)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IzgsceNFXU6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H19BUYgWF9vM"
      },
      "source": [
        "parameters = [{'n_estimators': [10, 15],\n",
        "'max_features': np.arange(3, 5),\n",
        "'max_depth': np.arange(4, 7)}]\n",
        "\n",
        "clf = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=100),\n",
        "    param_grid=parameters,\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOAv18j8GUwy"
      },
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ugLIqTRJzmZ"
      },
      "source": [
        "clf.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aanLg69KKVm7"
      },
      "source": [
        "y_pred = clf.predict_proba(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYHWkupHKr9E"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "y_pred_proba = y_pred[:, 1]\n",
        "y_pred_proba"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSrtu8PDZAIb"
      },
      "source": [
        "roc_auc_score(y_test, y_pred_proba)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kbdgP7hfGlE"
      },
      "source": [
        "*Дополнительные задания:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AirKhxDifI-W"
      },
      "source": [
        "1). Загрузите датасет Wine из встроенных датасетов sklearn.datasets с помощью функции load_wine в переменную data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJbli_WgfM0m"
      },
      "source": [
        "from sklearn.datasets import load_wine\n",
        "\n",
        "data = load_wine()\n",
        "# data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOL4x5FxflkN"
      },
      "source": [
        "2). Полученный датасет не является датафреймом. Это структура данных, имеющая ключи аналогично словарю. Просмотрите тип данных этой структуры данных и создайте список data_keys, содержащий ее ключи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAwluubHfoQQ"
      },
      "source": [
        "data_keys = data.keys()\n",
        "data_keys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPQ0OPC1f63W"
      },
      "source": [
        "3) Просмотрите данные, описание и названия признаков в датасете. Описание нужно вывести в виде привычного, аккуратно оформленного текста, без обозначений переноса строки, но с самими переносами и т.д.4). Сколько классов содержит целевая переменная датасета? Выведите названия классов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WugYbykGgAVN"
      },
      "source": [
        "descsiption = data['DESCR'].split(\"\\n\")\n",
        "for i in range(len(descsiption)):\n",
        "  print(f\"{descsiption[i]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwemhhdHjHHW"
      },
      "source": [
        "classes = data[\"target\"]\n",
        "# classes, type(classes)\n",
        "unique_elements, counts_elements = np.unique(classes, return_counts=True)\n",
        "unique_elements, counts_elements, data[\"target_names\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwx7P-xijiIy"
      },
      "source": [
        "5). На основе данных датасета (они содержатся в двумерном массиве Numpy) и названий признаков создайте датафрейм под названием X."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1qQGDOPk-Rw"
      },
      "source": [
        "X = pd.DataFrame(data=data['data'], columns=data['feature_names'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seFh_Gxqk69Y"
      },
      "source": [
        "6). Выясните размер датафрейма X и установите, имеются ли в нем пропущенные значения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMJ402aBkWwo"
      },
      "source": [
        "X.shape, X.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zfPWSaQlGI_"
      },
      "source": [
        "7). Добавьте в датафрейм поле с классами вин в виде чисел, имеющих тип данных numpy.int64. Название поля - 'target'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF2puRb-lG2n"
      },
      "source": [
        "X['target'] =  data[\"target\"].astype(np.int64)\n",
        "# X.shape, X.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwFsPNRXpHmi"
      },
      "source": [
        "8). Постройте матрицу корреляций для всех полей X. Дайте полученному датафрейму название X_corr."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvdt8Z3-pIYo"
      },
      "source": [
        "X_corr = X.corr()\n",
        "X_corr\n",
        "X_corr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5iuYWdCqVTc"
      },
      "source": [
        "9). Создайте список high_corr из признаков, корреляция которых с полем target по абсолютному значению превышает 0.5 (причем, само поле target не должно входить в этот список)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijwKnp-qW3D"
      },
      "source": [
        "f = X_corr.drop(columns=['target'])\n",
        "f.drop(index='target', inplace=True)\n",
        "\n",
        "high_corr = f[(np.abs(f)> 0.5) & (np.abs(f) < 1)]\n",
        "\n",
        "high_corr.dropna(axis=0, how='all', inplace=True)\n",
        "high_corr.dropna(axis=1, how='all', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8JxMKQjxHvF"
      },
      "source": [
        "10) Удалите из датафрейма X поле с целевой переменной. Для всех признаков, названия которых содержатся в списке high_corr, вычислите квадрат их значений и добавьте в датафрейм X соответствующие поля с суффиксом '_2', добавленного к первоначальному названию признака. Итоговый датафрейм должен содержать все поля, которые, были в нем изначально, а также поля с признаками из списка high_corr, возведенными в квадрат. Выведите описание полей датафрейма X с помощью метода describe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSKxNHrzxQHs"
      },
      "source": [
        "X.drop(columns='target', inplace=True, errors='ignore')\n",
        "\n",
        "for el in high_corr.columns:\n",
        "  X[el+'_2'] = X[el]**2\n",
        "\n",
        "X.describe()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}